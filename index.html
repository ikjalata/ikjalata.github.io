<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Ibsa Jalata</title>
  
  <meta name="author" content="Ibsa Jalata">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Ibsa Jalata</name> 
              </p>
              <p>I am a Ph.D. candidate at the University of Arkansas, focusing on Computer Vision, MRI image reconstruction, and action detection and localization using an Unsupervised Deep Learning approach. In 2017, I successfully completed my M.Sc. degree in Electronics and Information Engineering from Jeonbuk National University in South Korea. Prior to that, I earned my B.Sc. degree in Electrical and Computer Engineering from Addis Ababa University in Ethiopia.
              </p>
              
              <p style="text-align:center">
                <a href="mailto:ibsakum908@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=Q_3QbE8AAAAJ&hl=en&oi=ao">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/ikjalata/">Github</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/ibsa-jalata-07853b75
">LinkedIn</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/ibsa_dev.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/ibsa_dev.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in computer vision, machine learning and biomedical imaging. Representative papers are <span class="highlight">highlighted</span>.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
				

          <tr>
            <td style="padding:20px;width:40%;vertical-align:middle">
              <img src="images/oversample2.png" alt="safs_small" width="220" height="100" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://www.isvc.net/index.php/call-for-papers/">
                <papertitle>Learning from Oversampling: A Systematic Exploitation of oversampling to address Data Scarcity issues in Deep Learning based Magnetic Resonance Image Reconstruction</papertitle>
              </a>
              <br>
              <strong>Ibsa Jalata</strong>, <a href="https://scholar.google.com/citations?user=D3rO3W4AAAAJ&hl=en&oi=ao">Reeshad Khan</a>, <a href="https://unakarmi.github.io">Ukash Nakarmi</a>
              <br>
              <em>ISVC</em>, 2023
              
              <p>To address the scarcity of training data in MR image reconstruction, 
                we pose the training data oversampling as a one-to-many
                mapping function and introduce a new loss function based on
                similarity metric that can be integrated into a DL framework.
                In addition to solving the scarcity of the available data, this
                approach makes the learned model more robust to different
                under-sampling factors.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:40%;vertical-align:middle">
              <img src="images/unsuprevised_overall.png" alt="fast-texture" width="220" height="120">
            </td>
            <td width="75%" valign="middle">
              <a href="https://www.isvc.net/index.php/call-for-papers/">
                <papertitle>When System Model meets Image Prior: An
                  Unsupervised Deep Learning Architecture for
                  Accelerated Magnetic Resonance Imaging</papertitle>
              </a>
              <br>
              <strong>Ibsa Jalata</strong>, <a href="https://unakarmi.github.io">Ukash Nakarmi</a>
              <br>
              <em>ISVC</em>, 2023
              <br>
              
              <p> An unsupervised deep learning framework for
                accelerated MRI is proposed to overcome the limitation of
                ground truth images. Our framework combines a system prior
                derived from the MR acquisition model with generic image
                priors to build a more effective unsupervised deep learning
                framework. This approach addresses the slow sequential data
                acquisition issue and accelerates MRI without relying on supervised learning. 
                Experimental results validate its effectiveness.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:40%;vertical-align:middle">
              <img src="images/equipollent.png" alt="fast-texture" width="220" height="120">
            </td>
            <td width="75%" valign="middle">
              <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9874820">
                <papertitle>EQAdap: Equipollent Domain Adaptation Approach to Image Deblurring</papertitle>
              </a>
              <br>
              <strong>Ibsa Jalata</strong>, Naga Chappa, Thanh-dat Troung, Pierce Helton, Chase Rainwater, Khoa Luu
              <br>
              <em>IEEE-Access</em>, 2022
              <br>
              
              <p> The paper introduces an unsupervised domain adaptation method for image deblurring, aiming to improve generalization across different domains. 
                It focuses on learning a complex latent space from a source domain and applying that knowledge to an unlabeled target domain. 
                To address challenges with supervised methods that struggle to generalize in new environments, the paper introduces a novel Bijective Maximum Likelihood loss. 
                Experimental results on various datasets show that the proposed approach achieves state-of-the-art performance on standard benchmarks.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:40%;vertical-align:middle">
              <img src="images/non_volume_image.png" alt="fast-texture" width="220" height="120">
            </td>
            <td width="75%" valign="middle">
              <a href="https://www.sciencedirect.com/science/article/pii/S0031320322001273">
                <papertitle>Non-volume preserving-based fusion to group-level emotion recognition on crowd videos</papertitle>
              </a>
              <br>
              Kha Gia Quach, Ngan Lee, Chi Nhan Duong, <strong>Ibsa Jalata</strong>, Kaushik Roy, K. Luu
              <br>
              <em>Pattern Recognition</em>, 2022
              <br>
              
              <p> The study addresses the emerging field of group-level emotion recognition (ER) in response 
                to the demand for evaluating emotions in large crowds, both in security and social media contexts. 
                The paper introduces a deep feature fusion mechanism named Non-Volume Preserving Fusion (NVPF) to 
                effectively capture spatial-temporal information in crowd videos. 
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:40%;vertical-align:middle">
              <img src="images/movement.png" alt="fast-texture" width="220" height="120">
            </td>
            <td width="75%" valign="middle">
              <a href="https://www.mdpi.com/1999-5903/13/8/194">
                <papertitle>Movement Analysis for Neurological and Musculoskeletal Disorders Using Graph Convolutional Neural Network</papertitle>
              </a>
              <br>
              <strong>Ibsa K. Jalata</strong>, Thanh-dat Troung, Jessica L.Allen, Han-Seok Seo, K. Luu
              <br>
              <em>Future Internet-MDPI</em>, 2021
              <br>
              
              <p> The project introduces video-based neural network for accurate impaired movement analysis in 
                neurological and musculoskeletal disorders, replacing expensive motion capture methods. 
                Graph convolutional and 1D convolutional networks enhance correlation with ground truth gait measures and enable faster training. 
                Offers cost-effective alternative for patient-specific impairment identification 
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:40%;vertical-align:middle">
              <img src="images/mobiface.png" alt="fast-texture" width="220" height="100">
            </td>
            <td width="75%" valign="middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/9185981">
                <papertitle>Mobiface: A lightweight deep learning face recognition on mobile devices
                </papertitle>
              </a>
              <br>
              Chi Nhan Duong, Kha Gia Quach, <strong>Ibsa Jalata</strong>, Ngan Le, K. Luu
              <br>
              <em>IEEE 10th international conference on BTAS </em>, 2019
              <br>
              
              <p> The paper discusses the challenge of deploying accurate deep neural network-based face recognition on mobile 
                devices due to computational limitations. To address this, a lightweight network named MobiFace is introduced, 
                focusing on efficient memory usage, a small number of weights, and low-cost operators for mobile deployment
              </p>
            </td>
          </tr>

        </tbody></table>

				
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Professional Memberships</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td width="75%" valign="center">
              <a >IEEE Memberships</a>
              <br>
              <a >IEEE-EMBS Memberships</a>
            </td>
          </tr>
					
					
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
